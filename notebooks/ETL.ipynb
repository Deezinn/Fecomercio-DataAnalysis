{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc899578-9244-409e-9988-7a2b0707b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Diretório onde o arquivo será salvo\n",
    "directory = \"../datasets\"\n",
    "csv_directory = os.path.join(directory, \"csv\")  # Novo diretório para os CSVs\n",
    "\n",
    "# Verifica se o diretório CSV já existe, caso contrário, cria o diretório\n",
    "if not os.path.exists(csv_directory):\n",
    "    os.makedirs(csv_directory)\n",
    "\n",
    "class etBcb:\n",
    "    def __init__(self, api_link):\n",
    "        self.api_link = api_link\n",
    "        self.dados = None\n",
    "        self.df = None\n",
    "\n",
    "    def requisicao_api(self):\n",
    "        \"\"\"\n",
    "        Método GET para a API e armazenar a resposta.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            resposta = requests.get(self.api_link)\n",
    "            if resposta.status_code == 200:\n",
    "                self.dados = resposta.json()\n",
    "                print('Status Code:', resposta.status_code)\n",
    "            else:\n",
    "                print('Erro na requisição. Status Code:', resposta.status_code)\n",
    "        except Exception as e:\n",
    "            print('Erro ao fazer a requisição:', e)\n",
    "\n",
    "    def detectar_estrutura_json(self):\n",
    "        \"\"\"\n",
    "        Método para detectar a estrutura do JSON.\n",
    "        \"\"\"\n",
    "        # Verifica se a chave 'resultados' e 'series' existem\n",
    "        if isinstance(self.dados, list) and 'resultados' in self.dados[0] and 'series' in self.dados[0]['resultados'][0]:\n",
    "            return 'nova_serie'\n",
    "        else:\n",
    "            # Depuração: imprimir a estrutura do JSON para verificar o que está errado\n",
    "            print(\"Estrutura JSON não reconhecida. Aqui está o JSON retornado:\")\n",
    "            print(json.dumps(self.dados, indent=4))  # Imprime o JSON formatado para leitura\n",
    "            return 'desconhecida'\n",
    "\n",
    "    def transformar_dados(self):\n",
    "        \"\"\"\n",
    "        Método para transformar os dados JSON em um DataFrame pandas.\n",
    "        \"\"\"\n",
    "        if self.dados:\n",
    "            try:\n",
    "                estrutura = self.detectar_estrutura_json()\n",
    "\n",
    "                if estrutura == 'nova_serie':\n",
    "                    # Processamento para a nova estrutura com 'series'\n",
    "                    data_series = self.dados[0]['resultados'][0]['series'][0]['serie']\n",
    "                    # Transformando a série de dados em um DataFrame\n",
    "                    self.df = pd.DataFrame(list(data_series.items()), columns=['Data', 'Valor'])\n",
    "                    print('Transformação concluída para a nova estrutura com series.')\n",
    "                else:\n",
    "                    print('Estrutura JSON desconhecida.')\n",
    "                    \n",
    "            except KeyError as e:\n",
    "                print(f'Chave não encontrada no JSON: {e}')\n",
    "            except Exception as e:\n",
    "                print('Erro ao transformar os dados:', e)\n",
    "        else:\n",
    "            print('Nenhum dado para transformar.')\n",
    "\n",
    "    def salvar_sqlite(self, nome_tabela):\n",
    "        \"\"\"\n",
    "        Método para salvar o DataFrame transformado em um banco de dados SQLite.\n",
    "        \"\"\"\n",
    "        nome_banco = os.path.join(directory, 'Fecomdb.db')\n",
    "        if self.df is not None:\n",
    "            try:\n",
    "                with sqlite3.connect(nome_banco) as conexao:\n",
    "                    self.df.to_sql(nome_tabela, conexao, if_exists='replace', index=False)\n",
    "                    print(f'Dados salvos na tabela \"{nome_tabela}\" do banco de dados \"{nome_banco}\".')\n",
    "            except Exception as e:\n",
    "                print('Erro ao salvar os dados no banco de dados SQLite:', e)\n",
    "        else:\n",
    "            print('Nenhum dado para salvar no banco de dados.')\n",
    "\n",
    "    def salvar_csv(self, nome_arquivo):\n",
    "        \"\"\"\n",
    "        Método para salvar o DataFrame transformado em um arquivo CSV.\n",
    "        \"\"\"\n",
    "        if self.df is not None:\n",
    "            try:\n",
    "                self.df.to_csv(os.path.join(csv_directory, nome_arquivo), sep=';', decimal=',', encoding='utf-8-sig', index=False)\n",
    "                print(f'Dados salvos no arquivo CSV \"{nome_arquivo}\" na pasta \"csv\".')\n",
    "            except Exception as e:\n",
    "                print('Erro ao salvar o CSV:', e)\n",
    "        else:\n",
    "            print('Nenhum dado no CSV.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ae3ea56-9cff-42d8-82c2-72292cf27025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Transformação concluída para a nova estrutura com series.\n",
      "Dados salvos na tabela \"PMSCargaBrasil\" do banco de dados \"../datasets\\Fecomdb.db\".\n",
      "Dados salvos no arquivo CSV \"PMSCargaBrasil.csv\" na pasta \"csv\".\n"
     ]
    }
   ],
   "source": [
    "url = \"https://servicodados.ibge.gov.br/api/v3/agregados/8695/periodos/201101-202407/variaveis/11623?localidades=N1[all]&classificacao=11046[56726]|12355[56724]\"\n",
    "    \n",
    "    # Nome da tabela\n",
    "name_table = 'PMSCargaBrasil'\n",
    "\n",
    "    # Instanciar a classe ETL com o link da API\n",
    "etl = etBcb(url)\n",
    "\n",
    "    # Executar o método de requisição para extrair os dados da API\n",
    "etl.requisicao_api()\n",
    "\n",
    "    # Transformar os dados\n",
    "etl.transformar_dados()\n",
    "\n",
    "    # Salvar os dados no SQLite e no CSV\n",
    "etl.salvar_sqlite(name_table)\n",
    "etl.salvar_csv(f'{name_table}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d67411a-74c1-4942-8c45-f2dade322d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '11046', 'nome': 'Tipos de índice', 'categoria': {'56726': 'Índice de volume de serviços'}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url ='https://servicodados.ibge.gov.br/api/v3/agregados/8688/periodos/201102-202407/variaveis/11623?localidades=N1[all]&classificacao=11046[56726]|12355[107071,106869,106874,31399,106876,31426]'\n",
    "data = pd.read_json(url)\n",
    "print(data['resultados'][0][0]['classificacoes'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
